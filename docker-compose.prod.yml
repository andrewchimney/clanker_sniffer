networks:
  web: {}   # public edge; only traefik + frontend join this

services:
  traefik:
    image: traefik:v2.10
    container_name: traefik
    restart: unless-stopped
    command:
      - --providers.docker=true
      - --providers.docker.exposedbydefault=false
      - --entrypoints.web.address=:80
      - --entrypoints.web.http.redirections.entryPoint.to=websecure
      - --entrypoints.web.http.redirections.entryPoint.scheme=https
      - --entrypoints.websecure.address=:443
      - --certificatesresolvers.le.acme.httpchallenge=true
      - --certificatesresolvers.le.acme.httpchallenge.entrypoint=web
      - --certificatesresolvers.le.acme.email=andrewchimney@gmail.com
      - --certificatesresolvers.le.acme.storage=/letsencrypt/acme.json
      # - --accesslog=true
      # - --accesslog.format=json
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./letsencrypt:/letsencrypt
    networks: [web]
  frontend:
    build:
      context: ./frontend
      target: runner 
    container_name: clanker_frontend
    depends_on:
      orchestrator_api:
        condition: service_healthy
    restart: unless-stopped
    environment:
      DATABASE_URL: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
      CHOKIDAR_USEPOLLING: "true"
    # remove host port publish:
    # ports: ["3000:3000"]
    expose: ["3000"]
    working_dir: /app
    command: ["npm","run","start"]
    volumes:
      - ./shared_data:/shared_data:ro
    env_file: [./.env]
    networks: [web, default]             # public via traefik + internal to talk to API
    labels:
      - traefik.enable=true
      - traefik.docker.network=clanker_sniffer_web
      - traefik.http.routers.frontend.rule=Host(`clankr.app`,`www.clankr.app`)
      - traefik.http.routers.frontend.entrypoints=websecure
      - traefik.http.routers.frontend.tls.certresolver=le
      - traefik.http.services.frontend.loadbalancer.server.port=3000
      # optional hardening:
      - traefik.http.middlewares.hsts.headers.stsSeconds=31536000
      - traefik.http.middlewares.hsts.headers.stsIncludeSubdomains=true
      - traefik.http.routers.frontend.middlewares=hsts
  db:
    image: postgres:15
    container_name: clanker_db
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
      - ./shared_data:/shared_data
    command:
      - "postgres"
      - "-c"
      - "log_timezone=UTC"                      # match your appâ€™s UTC timestamps
      - "-c"
      - "log_min_messages=info"                 # show INFO and above
      - "-c"
      - "log_min_error_statement=info"
      - "-c"
      - "client_min_messages=notice"
      - "-c"
      - "log_line_prefix=%m %s:     clanker_db %u@%d app=%a [%p] "
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB -h localhost"]
      interval: 100s
      timeout: 5s
      retries: 5
      start_period: 20s

  demucs_api:
    build: ./demucs-api
    container_name: clanker_demucs
    restart: unless-stopped
    volumes:
      - ./demucs-api:/app
      - ./shared_data:/shared_data
    working_dir: /app
    expose:
      - "8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 100s
      timeout: 3s
      retries: 30
      start_period: 20s


  whisper_api:
    build: ./whisper-api
    container_name: clanker_whisper
    restart: unless-stopped
    volumes:
      - ./whisper-api:/app
      - ./shared_data:/shared_data
    working_dir: /app
    env_file:
      - ./.env
    expose:
      - "8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 100s
      timeout: 3s
      retries: 30
      start_period: 20s


  classifier_api:
    build: ./classifier-api
    container_name: clanker_classifier
    restart: unless-stopped
    volumes:
      - ./classifier-api:/app
      - ./shared_data:/shared_data
    working_dir: /app
    expose:
      - "8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 100s
      timeout: 3s
      retries: 30
      start_period: 20s

  acousti_api:
    build: ./acousti-api
    container_name: clanker_acousti
    restart: unless-stopped
    volumes:
      - ./acousti-api:/app
      - ./shared_data:/shared_data
    working_dir: /app
    env_file:
      - ./.env
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 100s
      timeout: 3s
      retries: 30
      start_period: 20s
  orchestrator_api:
    build: ./orchestrator-api
    container_name: clanker_orchestrator
    depends_on:
      db:
        condition: service_healthy
      demucs_api:
        condition: service_healthy
      whisper_api:
        condition: service_healthy
      classifier_api:
        condition: service_healthy
      acousti_api:
        condition: service_healthy
    volumes:
      - ./orchestrator-api:/app
      - ./shared_data:/shared_data
    working_dir: /app
    env_file:
      - ./.env
    expose:
      - "8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 100s
      timeout: 3s
      retries: 30
      start_period: 20s

  fluentd:
    build: ./fluentd
    user: "0:0"                      # keep root so it can read /var/lib/docker/containers
    restart: unless-stopped
    environment:
      FLUENT_UID: "0"
      OCI_CONFIG_FILE: /fluentd/oci_config      # <-- explicit path to your config file
    volumes:
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - ./fluentd/fluent.conf:/fluentd/etc/fluent.conf:ro
      - ./fluentd/oci_api_key.pem:/fluentd/oci_api_key.pem:ro
      - ./fluentd/oci_config:/fluentd/oci_config:ro  # <-- mount the file here
        


volumes:
  pgdata:
